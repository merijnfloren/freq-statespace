{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parallel Wiener-Hammerstein system\n",
    "\n",
    "See http://arxiv.org/pdf/1708.06543 for more information on the dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '..')\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import nonlinear_benchmarks as nlb\n",
    "import numpy as np\n",
    "import optimistix as optx\n",
    "\n",
    "from src import best_linear_approximation as bla\n",
    "from src import data_manager\n",
    "\n",
    "np.random.seed(42)  # for reproducibility\n",
    "\n",
    "# Load data\n",
    "ParWH_full_train, ParWH_full_test = nlb.ParWH() \n",
    "\n",
    "# Initialise variables\n",
    "N = 16384  # number of samples per period\n",
    "R = 5  # number of random phase multisine realisations\n",
    "P = 2  # number of periods\n",
    "amplitude_level = 4  # must be one of {0, 1, 2, 3, 4}\n",
    "\n",
    "nu, ny = 1, 1  # SISO system\n",
    "\n",
    "fs = 78e3 # [Hz]\n",
    "f_idx = np.arange(1, 4096)  # frequency lines of interest (excludes DC)\n",
    "\n",
    "# Load data\n",
    "ParWH_full_train, ParWH_full_test = nlb.ParWH() \n",
    "ParWH_train = [\n",
    "    data for data in ParWH_full_train\n",
    "    for phase in range(R)\n",
    "    if data.name == f'Est-phase-{phase}-amp-{amplitude_level}'\n",
    "]\n",
    "ParWH_test = [\n",
    "    data for data in ParWH_full_test\n",
    "    if data.name == f'Val-amp-{amplitude_level}'\n",
    "][0]\n",
    "\n",
    "# Preprocess data\n",
    "u_train = np.array([data.u for data in ParWH_train]).reshape(R, nu, N, P)\n",
    "y_train = np.array([data.y for data in ParWH_train]).reshape(R, ny, N, P)\n",
    "u_train = np.transpose(u_train, (2, 1, 0, 3))\n",
    "y_train = np.transpose(y_train, (2, 1, 0, 3))\n",
    "\n",
    "u_test = np.transpose(ParWH_test.u.reshape(1, nu, N, 2), (2, 1, 0, 3))\n",
    "y_test = np.transpose(ParWH_test.y.reshape(1, ny, N, 2), (2, 1, 0, 3))\n",
    "\n",
    "# Create input-output training data object\n",
    "io_data = data_manager.create_data_object(u_train, y_train, f_idx, fs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 1: Best Linear Approximation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NRMSE of FSID BLA: 13.31%\n",
      "\n",
      "Starting iterative optimization...\n",
      "   Iteration 0, Loss: 1.0901e+00\n",
      "   Iteration 1, Loss: 8.7186e-01\n",
      "   Iteration 2, Loss: 8.7186e-01\n",
      "   Iteration 3, Loss: 8.7186e-01\n",
      "   Iteration 4, Loss: 8.6039e-01\n",
      "   Iteration 5, Loss: 8.6039e-01\n",
      "   Iteration 6, Loss: 7.9238e-01\n",
      "   Iteration 7, Loss: 7.7413e-01\n",
      "   Iteration 8, Loss: 7.5685e-01\n",
      "   Iteration 9, Loss: 7.4428e-01\n",
      "   Iteration 10, Loss: 7.3171e-01\n",
      "   Iteration 11, Loss: 7.2014e-01\n",
      "   Iteration 12, Loss: 7.1208e-01\n",
      "   Iteration 13, Loss: 7.0800e-01\n",
      "   Iteration 14, Loss: 7.0613e-01\n",
      "   Iteration 15, Loss: 7.0507e-01\n",
      "   Iteration 16, Loss: 7.0431e-01\n",
      "   Iteration 17, Loss: 7.0369e-01\n",
      "   Iteration 18, Loss: 7.0315e-01\n",
      "   Iteration 19, Loss: 7.0263e-01\n",
      "   Iteration 20, Loss: 7.0213e-01\n",
      "   Iteration 21, Loss: 7.0162e-01\n",
      "   Iteration 22, Loss: 7.0108e-01\n",
      "   Iteration 23, Loss: 7.0047e-01\n",
      "   Iteration 24, Loss: 6.9977e-01\n",
      "   Iteration 25, Loss: 6.9889e-01\n",
      "   Iteration 26, Loss: 6.9889e-01\n",
      "   Iteration 27, Loss: 6.9783e-01\n",
      "   Iteration 28, Loss: 6.9783e-01\n",
      "   Iteration 29, Loss: 6.9656e-01\n",
      "   Iteration 30, Loss: 6.9500e-01\n",
      "   Iteration 31, Loss: 6.9500e-01\n",
      "   Iteration 32, Loss: 6.8109e-01\n",
      "   Iteration 33, Loss: 6.8109e-01\n",
      "   Iteration 34, Loss: 6.6713e-01\n",
      "   Iteration 35, Loss: 6.6492e-01\n",
      "   Iteration 36, Loss: 6.6492e-01\n",
      "   Iteration 37, Loss: 6.6492e-01\n",
      "   Iteration 38, Loss: 6.6111e-01\n",
      "   Iteration 39, Loss: 6.5575e-01\n",
      "   Iteration 40, Loss: 6.5493e-01\n",
      "   Iteration 41, Loss: 6.5350e-01\n",
      "   Iteration 42, Loss: 6.5228e-01\n",
      "   Iteration 43, Loss: 6.5131e-01\n",
      "   Iteration 44, Loss: 6.5063e-01\n",
      "   Iteration 45, Loss: 6.5012e-01\n",
      "   Iteration 46, Loss: 6.4975e-01\n",
      "   Iteration 47, Loss: 6.4948e-01\n",
      "   Iteration 48, Loss: 6.4927e-01\n",
      "   Iteration 49, Loss: 6.4911e-01\n",
      "   Iteration 50, Loss: 6.4883e-01\n",
      "   Iteration 51, Loss: 6.4853e-01\n",
      "   Iteration 52, Loss: 6.4843e-01\n",
      "   Iteration 53, Loss: 6.4836e-01\n",
      "   Iteration 54, Loss: 6.4790e-01\n",
      "   Iteration 55, Loss: 6.4723e-01\n",
      "   Iteration 56, Loss: 6.4687e-01\n",
      "   Iteration 57, Loss: 6.4674e-01\n",
      "   Iteration 58, Loss: 6.4667e-01\n",
      "   Iteration 59, Loss: 6.4664e-01\n",
      "   Iteration 60, Loss: 6.4661e-01\n",
      "   Iteration 61, Loss: 6.4659e-01\n",
      "   Iteration 62, Loss: 6.4658e-01\n",
      "   Iteration 63, Loss: 6.4657e-01\n",
      "   Iteration 64, Loss: 6.4657e-01\n",
      "   Iteration 65, Loss: 6.4656e-01\n",
      "   Iteration 66, Loss: 6.4655e-01\n",
      "   Iteration 67, Loss: 6.4655e-01\n",
      "   Iteration 68, Loss: 6.4654e-01\n",
      "   Iteration 69, Loss: 6.4654e-01\n",
      "   Iteration 70, Loss: 6.4654e-01\n",
      "   Iteration 71, Loss: 6.4654e-01\n",
      "   Iteration 72, Loss: 6.4653e-01\n",
      "   Iteration 73, Loss: 6.4653e-01\n",
      "   Iteration 74, Loss: 6.4652e-01\n",
      "   Iteration 75, Loss: 6.4651e-01\n",
      "   Iteration 76, Loss: 6.4651e-01\n",
      "   Iteration 77, Loss: 6.4650e-01\n",
      "   Iteration 78, Loss: 6.4649e-01\n",
      "   Iteration 79, Loss: 6.4649e-01\n",
      "   Iteration 80, Loss: 6.4649e-01\n",
      "   Iteration 81, Loss: 6.4649e-01\n",
      "   Iteration 82, Loss: 6.4648e-01\n",
      "   Iteration 83, Loss: 6.4648e-01\n",
      "   Iteration 84, Loss: 6.4648e-01\n",
      "   Iteration 85, Loss: 6.4648e-01\n",
      "   Iteration 86, Loss: 6.4647e-01\n",
      "   Iteration 87, Loss: 6.4647e-01\n",
      "   Iteration 88, Loss: 6.4647e-01\n",
      "   Iteration 89, Loss: 6.4647e-01\n",
      "   Iteration 90, Loss: 6.4647e-01\n",
      "   Iteration 91, Loss: 6.4647e-01\n",
      "   Iteration 92, Loss: 6.4646e-01\n",
      "   Iteration 93, Loss: 6.4646e-01\n",
      "   Iteration 94, Loss: 6.4646e-01\n",
      "   Iteration 95, Loss: 6.4646e-01\n",
      "   Iteration 96, Loss: 6.4646e-01\n",
      "   Iteration 97, Loss: 6.4646e-01\n",
      "   Iteration 98, Loss: 6.4646e-01\n",
      "   Iteration 99, Loss: 6.4646e-01\n",
      "   Iteration 100, Loss: 6.4646e-01\n",
      "   Iteration 101, Loss: 6.4646e-01\n",
      "   Iteration 102, Loss: 6.4646e-01\n",
      "   Iteration 103, Loss: 6.4646e-01\n",
      "   Iteration 104, Loss: 6.4646e-01\n",
      "   Iteration 105, Loss: 6.4646e-01\n",
      "   Iteration 106, Loss: 6.4646e-01\n",
      "   Iteration 107, Loss: 6.4646e-01\n",
      "   Iteration 108, Loss: 6.4646e-01\n",
      "\n",
      "\n",
      "NRMSE of opti BLA: 11.18%\n",
      "\n",
      "Standard deviation of states: [1.069405  1.0281874 1.0212054 1.0169773 1.0145999 1.0142895 1.0144198\n",
      " 1.0158699 1.0139703 1.0158455 1.0141473 1.0161258]\n"
     ]
    }
   ],
   "source": [
    "##### (i) Nonparametric estimate #####\n",
    "G_nonpar = bla.compute_nonparametric(io_data)\n",
    " \n",
    "##### (ii) Parametrize using frequency-domain subspace identification method #####\n",
    "nx = 12  # number of states\n",
    "q = nx + 1  # subspace dimensioning parameter\n",
    "bla_fsid = bla.freq_subspace_id(G_nonpar, nx, q)\n",
    "\n",
    "# Simulate and check time-domain performance\n",
    "u_bar = np.mean(io_data.time.u, axis=-1)  # we take the mean over the periods\n",
    "y_bar = np.mean(io_data.time.y, axis=-1)  # we take the mean over the periods\n",
    "handicap = 1000  # number of samples to start 'ahead of time' for transient effects to die out (only works for periodic data!)\n",
    "\n",
    "y_sim_bla_fsid = bla_fsid.simulate(u_bar, handicap=handicap)[0]\n",
    "NRMSE_bla_fsid = 100 * np.sqrt(np.mean((y_bar - y_sim_bla_fsid)**2)) / np.sqrt(np.mean(y_bar**2)) \n",
    "\n",
    "print(f'NRMSE of FSID BLA: {NRMSE_bla_fsid:.2f}%\\n')\n",
    "\n",
    "##### (iii) Frequency-domain iterative optimization starting from FSID BLA #####\n",
    "solver = optx.LevenbergMarquardt(rtol=1e-3, atol=1e-6)\n",
    "max_iter = 1000\n",
    "\n",
    "bla_opti = bla.freq_iterative_optimization(G_nonpar, bla_fsid, solver, max_iter)\n",
    "\n",
    "# Simulate and check time-domain performance\n",
    "y_sim_bla_opti = bla_opti.simulate(u_bar, handicap=handicap)[0]\n",
    "NRMSE_bla_opti = 100 * np.sqrt(np.mean((y_bar - y_sim_bla_opti)**2)) / np.sqrt(np.mean(y_bar**2)) \n",
    "\n",
    "print(f'NRMSE of opti BLA: {NRMSE_bla_opti:.2f}%\\n')\n",
    "\n",
    "x_sim_bla_opti = bla_opti.simulate(u_bar, handicap=handicap)[1]\n",
    "x_std = np.std(x_sim_bla_opti, axis=(0,2))\n",
    "print(f'Standard deviation of states: {x_std}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'G_par' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m G_parr \u001b[38;5;241m=\u001b[39m \u001b[43mG_par\u001b[49m\u001b[38;5;241m.\u001b[39mfrequency_response(io_data\u001b[38;5;241m.\u001b[39mfreq\u001b[38;5;241m.\u001b[39mf[io_data\u001b[38;5;241m.\u001b[39mfreq\u001b[38;5;241m.\u001b[39mf_idx])\n\u001b[1;32m      3\u001b[0m plt\u001b[38;5;241m.\u001b[39mfigure()\n\u001b[1;32m      4\u001b[0m plt\u001b[38;5;241m.\u001b[39mplot( \u001b[38;5;241m20\u001b[39m\u001b[38;5;241m*\u001b[39mnp\u001b[38;5;241m.\u001b[39mlog10(np\u001b[38;5;241m.\u001b[39mabs(G_parr\u001b[38;5;241m.\u001b[39msqueeze())), label\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mParametric Model\u001b[39m\u001b[38;5;124m'\u001b[39m, color\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mC0\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'G_par' is not defined"
     ]
    }
   ],
   "source": [
    "G_parr = G_par.frequency_response(io_data.freq.f[io_data.freq.f_idx])\n",
    "\n",
    "plt.figure()\n",
    "plt.plot( 20*np.log10(np.abs(G_parr.squeeze())), label='Parametric Model', color='C0')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as mcolors\n",
    "\n",
    "# Generate random values between 0 and 100\n",
    "np.random.seed(42)\n",
    "data = np.random.randint(0, 101, (5, 5))  # 5x5 table\n",
    "\n",
    "# Create a colormap from red to green\n",
    "cmap = mcolors.LinearSegmentedColormap.from_list(\"custom\", [\"red\", \"green\"])\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(5, 5))\n",
    "\n",
    "# Remove axis ticks\n",
    "ax.set_xticks([])\n",
    "ax.set_yticks([])\n",
    "\n",
    "# Display table-like heatmap\n",
    "for i in range(data.shape[0]):\n",
    "    for j in range(data.shape[1]):\n",
    "        value = data[i, j]\n",
    "        color = cmap(value / 100)  # Normalize to [0,1] for colormap\n",
    "        ax.add_patch(plt.Rectangle((j, -i), 1, 1, color=color))\n",
    "        ax.text(j + 0.5, -i + 0.5, f\"{value}\", ha='center', va='center', color=\"black\")\n",
    "\n",
    "# Adjust limits\n",
    "ax.set_xlim(0, data.shape[1])\n",
    "ax.set_ylim(-data.shape[0], 0)\n",
    "ax.set_aspect(\"equal\")\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estimate the best linear approximation\n",
    "nx = 12\n",
    "q = nx + 3\n",
    "\n",
    "optim_options = bla_optimisation.OptiOptions(\n",
    "    solver = optx.LevenbergMarquardt(rtol=1e-3, atol=1e-6),\n",
    "    max_iter = 100\n",
    ")\n",
    "\n",
    "IDM.freq_subspace_id(nx, q, W='std_tot', optim_options=optim_options)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "polynomial_degree = 7\n",
    "nw = 2\n",
    "nz = 2\n",
    "\n",
    "phi = basis_functions.Polynomial(nz=nz, cross_terms=False, degree=polynomial_degree)\n",
    "\n",
    "lambda_w = 1\n",
    "fixed_point_iters = 10\n",
    "solver = optx.LevenbergMarquardt(rtol=1e-3, atol=1e-6, verbose=frozenset({'step', 'loss', 'accepted'}))\n",
    "# solver = optx.BFGS(rtol=1e-3, atol=1e-6)\n",
    "freeze_bla = True\n",
    "seed = 3\n",
    "\n",
    "mod = nonlinear_lfr_init.init(IDM, nw=nw, phi=phi, lambda_w=lambda_w, fixed_point_iters=fixed_point_iters, solver=solver, freeze_bla=freeze_bla, seed=seed, max_iter=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimise one-step-ahead state predictions (optional)\n",
    "ModelNonlinearLFR_opti = nonlinear_lfr_opti.optimise_state_predictions(\n",
    "    IDM,\n",
    "    solver=optx.BFGS(rtol=1e-8, atol=1e-8),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Optimise one-step-ahead state predictions (optional)\n",
    "# ModelNonlinearLFR_opti = nonlinear_lfr_opti.optimise_state_predictions(\n",
    "#     IDM,\n",
    "#     solver=optx.BFGS(rtol=1e-8, atol=1e-8),\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimise simulation error# Optimise one-step-ahead state predictions (optional)\n",
    "# ModelNonlinearLFR_opti = nonlinear_lfr_opti.optimise_state_predictions(\n",
    "#     IDM,\n",
    "#     solver=optx.BFGS(rtol=1e-8, atol=1e-8),\n",
    "# )\n",
    "\n",
    "from reinbos.utils import misc\n",
    "\n",
    "custom_init = nonlinear_lfr_opti.DecisionVars(\n",
    "    B_w=misc.OptiParam(1/10*ModelNonlinearLFR.B_w),\n",
    "    D_yw=misc.OptiParam(1/10*ModelNonlinearLFR.D_yw),\n",
    ")\n",
    "\n",
    "\n",
    "ModelNonlinearLFR_opti_sim = nonlinear_lfr_opti.optimise_simulation_error(\n",
    "    IDM,\n",
    "    solver=optx.LevenbergMarquardt(rtol=1e-3, atol=1e-6),\n",
    "    max_iter=200,\n",
    "    custom_init=custom_init,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model on test data\n",
    "ParWH_test = [\n",
    "    data for data in ParWH_full_test\n",
    "    if data.name == f'Val-amp-{amp_level}' or data.name == 'ValArr'\n",
    "]\n",
    "\n",
    "test_ms = ParWH_test[0]\n",
    "test_arr = ParWH_test[2]\n",
    "\n",
    "# Multisine test\n",
    "u_test_ms = np.transpose(test_ms.u.reshape(1, nu, N, 2), (2, 1, 0, 3))\n",
    "y_test_ms = test_ms.y[::2]\n",
    "u_test_ms = (u_test_ms - u_mean) / u_std\n",
    "\n",
    "y_bla_ms = IDM.bla.opti.model.simulate(u_test_ms)[1]\n",
    "y_lfr_ms = ModelNonlinearLFR_opti_sim.simulate(u_test_ms)[2]\n",
    "y_bla_ms = np.squeeze(y_bla_ms[..., 1] * y_std + y_mean)\n",
    "y_lfr_ms = np.squeeze(y_lfr_ms[..., 1] * y_std + y_mean)\n",
    "\n",
    "e_bla_ms = y_test_ms - y_bla_ms\n",
    "e_lfr_ms = y_test_ms - y_lfr_ms\n",
    "\n",
    "E_bla_ms = 1 / N * np.fft.rfft(e_bla_ms, axis=0)\n",
    "E_lfr_ms = 1 / N * np.fft.rfft(e_lfr_ms, axis=0)\n",
    "Y_test_ms = 1 / N * np.fft.rfft(y_test_ms, axis=0)\n",
    "\n",
    "print(f'Multisine test RMSE BLA: {np.sqrt(np.mean(e_bla_ms**2)):.4e} ({100*np.std(e_bla_ms)/np.std(y_test_ms):.2f}%)')\n",
    "print(f'Multisine test RMSE nonlinear LFR: {np.sqrt(np.mean(e_lfr_ms**2)):.4e} ({100*np.std(e_lfr_ms)/np.std(y_test_ms):.2f}%)')\n",
    "\n",
    "fig, axs = plt.subplots(1, 2, figsize=(15, 5))\n",
    "axs[0].plot(IDM.data.time.t, y_test_ms, label='system output')\n",
    "axs[0].plot(IDM.data.time.t, e_bla_ms, label='BLA error')\n",
    "axs[0].plot(IDM.data.time.t, e_lfr_ms, label='nonlinear LFR error')\n",
    "axs[0].set_title('Multisine - Time Domain')\n",
    "axs[0].set_xlabel('time [s]')\n",
    "axs[0].set_ylabel('amplitude [-]')\n",
    "axs[0].legend()\n",
    "\n",
    "axs[1].plot(IDM.data.freq.f[f_idx], 20*np.log10(np.abs(Y_test_ms[f_idx])), label='system output')\n",
    "axs[1].plot(IDM.data.freq.f[f_idx], 20*np.log10(np.abs(E_bla_ms[f_idx])), label='BLA error')\n",
    "axs[1].plot(IDM.data.freq.f[f_idx], 20*np.log10(np.abs(E_lfr_ms[f_idx])), label='nonlinear LFR error')\n",
    "axs[1].set_title('Multisine - Frequency Domain')\n",
    "axs[1].set_xlabel('frequency [Hz]')\n",
    "axs[1].set_ylabel('magnitude [dB]')\n",
    "axs[1].legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# Arrow test\n",
    "u_test_arr = test_arr.u.reshape(-1, 1, 1)\n",
    "u_test_arr = (u_test_arr - u_mean) / u_std\n",
    "y_test_arr = test_arr.y\n",
    "\n",
    "y_bla_ss = IDM.bla.opti.model.simulate(u_test_arr, P_trans=1)[1]\n",
    "y_lfr_ss = ModelNonlinearLFR_opti_sim.simulate(u_test_arr, P_trans=1)[2]\n",
    "y_bla_ss = np.squeeze(y_bla_ss * y_std + y_mean)\n",
    "y_lfr_ss = np.squeeze(y_lfr_ss * y_std + y_mean)\n",
    "\n",
    "e_bla_ss = y_test_arr - y_bla_ss\n",
    "e_lfr_ss = y_test_arr - y_lfr_ss\n",
    "\n",
    "print(f'Arrow test RMSE BLA: {np.sqrt(np.mean(e_bla_ss**2)):.4e} ({100*np.std(e_bla_ss)/np.std(y_test_arr):.2f}%)')\n",
    "print(f'Arrow test RMSE nonlinear LFR: {np.sqrt(np.mean(e_lfr_ss**2)):.4e} ({100*np.std(e_lfr_ss)/np.std(y_test_arr):.2f}%)')\n",
    "\n",
    "t_ss = np.linspace(0, len(y_test_arr) / fs, len(y_test_arr))\n",
    "\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.plot(t_ss, y_test_arr, label='system output')\n",
    "plt.plot(t_ss, e_bla_ss, label='BLA error')\n",
    "plt.plot(t_ss, e_lfr_ss, label='nonlinear LFR error')\n",
    "plt.title('Arrow test - Time Domain')\n",
    "plt.xlabel('time [s]')\n",
    "plt.ylabel('amplitude [-]')\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
